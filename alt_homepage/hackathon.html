
	
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Machine Learning Hackathon</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<link rel="shortcut icon" href="favicon.ico">
	
	<link href='https://fonts.googleapis.com/css?family=Work+Sans:400,300,600,700' rel='stylesheet' type='text/css'>
	<link href='https://fonts.googleapis.com/css?family=Playfair+Display:400,400italic,700italic,700' rel='stylesheet' type='text/css'>
	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Flexslider -->
	<link rel="stylesheet" href="css/flexslider.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">

	<link rel="stylesheet" id="theme-switch" href="css/style.css">


	<!-- jQuery -->
	<script src="js/jquery.min.js"></script>
	<!-- jQuery Cookie -->
	<script src="js/jquery.cookie.js"></script>
	<script>
	if ( $.cookie('styleCookie') === 'style-light.css') {
		$('html, body').css('background', '#eeeeee');
	} else if ($.cookie('styleCookie') === 'style.css') {
		$('html, body').css('background', '#222222');
	}
	
	</script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Flexslider -->
	<script src="js/jquery.flexslider-min.js"></script>

	<!-- Viewport Units Buggyfill -->
	<script src="js/viewport-units-buggyfill.js"></script>

	<!-- Googgle Map -->
	<script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyCefOgb1ZWqYtj7raVSmN4PL2WkTrc-KyA&sensor=false"></script>
	<script src="js/google_map.js"></script>

	
	<!-- Main JS  -->
	<script src="js/main.js"></script>

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>

	<body>
	
	<!-- Loader -->
	<div class="sage-loader"></div>
	
	<div id="sage-page">
		<nav id="sage-nav" role="navigation">
			<ul>
				<li class="animate-box"><a href="lab0.html" class="transition">Lab 0</a></li>
				<li class="animate-box"><a href="lab1.html" class="transition">Lab 1</a></li>
				<li class="animate-box"><a href="lab2.html" class="transition">Lab 2</a></li>
				<li class="animate-box"><a href="lab3.html" class="transition">Lab 3</a></li>
				<li class="animate-box"><a href="lab4.html" class="transition">Lab 4</a></li>
				<li class="animate-box"><a href="lab5.html" class="transition">Lab 5</a></li>
				<li class="animate-box"><a href="lab6.html" class="transition">Lab 6</a></li>
			</ul>
		</nav>
		
		<header id="sage-header" role="banner" class="sage-project js-sage-waypoint no-border" data-colorbg="#222222" data-next="yes">
			<div class="container">
				<div class="sage-text-wrap animate-box">
						<center><img src="images/sagemkr.png" height="150px" width="150px"><p>
						<h1>Machine Learning Hackathon</h1>
						<h2>Hosted by <a href="http://aws.amazon.com/" target="_blank">Amazon Web Services</a>&nbsp;<img src="images/aws_logo.png" height="50px" width="75px"></h2>
						</center>
				</div>
			</div>

				<div class="btn-next animate-box sage-learn-more">
				<a href="#agenda" class="scroll">
					<center><span style="color: #222222;">Agenda Below</span></center>
					<i class="icon-chevron-down"></i>
				</a>
				</div>
			</header>

			<div class="js-sage-waypoint sage-project-detail" id="sage-main" data-colorbg="">
			<div class="container">
				<div class="animate-box" style="width:100%; height:100%;">
					This 3-day hackathon is designed to give developers, data scientists and architects experience in building end-to-end machine learning workloads. We will be following the CRISP-DM (CRoss-Industry Standard Process for Data Mining) process shown below:
					<br>
					<center><img src="images/CRISP_en.png" style="width:50%"></center><br>

					The life cycle model consists of six phases with arrows indicating the most important and frequent dependencies between phases. The sequence of the phases is not strict. In fact, most projects move back and forth between phases as necessary. Detailed information can be obtained <a href="https://www.the-modeling-agency.com/crisp-dm.pdf">here</a> and <a href="https://inseaddataanalytics.github.io/INSEADAnalytics/CRISP_DM.pdf">here.</a> Days will be broken down into the following sessions:<br>

					<hr>
					<div id="agenda"></div>
						<center><h3>Day 1</h3></center>
						  <h4>Session 1 - Business Understanding</h4>
						  	  <ul>
						  	  	<li>What does your business hope to gain from this project?</li>
						  	  	<li>How will you define the successful completion of our efforts?</li>
						  	  	<li>Do you have the budget and resources needed to reach our goals?</li>
						  	  	<li>Do you have access to all the data needed for this project?</li>
						  	  	<li>Have you and your team discussed the risks and contingencies associated with this project?</li>
						  	  	<li>Do the results of your cost/benefit analysis make this project worthwhile?</li>
						  	  </ul>
						  	  <br>

						  	  <h5> DELIVERABLES - Business Objectives Report</h5>
						  	  <ol>
						  	  <li><i>Objective</i></li>
						  	  <li><i>Roles</i></li>
						  	  <li><i>Success Criteria for your ML model</i></li>
						  	  <li><i>Initial Cost Assessment </i></li>
						  	  </ol>
						  	  <br>

					<hr>
						  <h4>Session 2 - Data Understanding</h4>
						  	  <ul>

  								<li>Are all data sources clearly identified and accessed? Are you aware of any problems or restrictions?</li>
  								<li>Have you identified key attributes from the available data?</li>
  								<li>Did these attributes help you to formulate hypotheses?</li>
  								<li>Have you noted the size of all data sources?</li>
  								<li>Are you able to use a subset of data where appropriate?</li>
  								<li>Have you computed basic statistics for each attribute of interest? Did meaningful information emerge?</li>
  								<li>Did you use exploratory graphics to gain further insight into key attributes? Did this insight reshape any of your hypotheses?</li>
  								<li>What are the data quality issues for this project? Do you have a plan to address these issues?   </li>
  								<li>Are the data preparation steps clear? For instance, do you know which data sources to merge and which attributes to filter or select</li>

						  	  </ul>
						  	  <br>

						  	  <h5> DELIVERABLES - Data Report</h5>
						  	  <ol>
						  	  <li><i>Data quantity (size and format)</i></li>
						  	  <li><i>Data quality (missing data, data errors, basic statistics, prioritize relevant attributes)</i></li>
						  	</ol>
					
					  	  <br>
					<hr>

						<h4>Session 3 - Data Preparation</h4>
						  	  Data preparation is one of the most important and often time-consuming aspects of data mining. In fact, it is estimated that data preparation usually takes 50-70% of a project’s time and effort. Devoting adequate energy to the earlier business understanding and data understanding phases can minimize this overhead, but you still need to expend a good amount of effort preparing and packaging the data for mining. Depending on your problem and your goals, data preparation typically involves the following tasks:
  								<ul>
  								<li>Merging data sets and/or records</li>
  								<li>Selecting a sample subset of data</li>
  								<li>Aggregating records</li>
								<li>Deriving new attributes</li>
								<li>Reduce imbalanced data</li>
								<li>Sorting the data for modeling</li>
  								<li>Removing or replacing blank or missing values</li>
  								<li>Feature Selection</li>
  								<li>Splitting into training, test and validate data sets</li>
  								</ul>

						  	  <br>

						  	  <h5> DELIVERABLES - (ML-ready) Data!</h5>
						  	  <ol>
						  	  <li><i>Data in S3 or Spark</i></li>
						  	  <li><i>Note that data prep for ML depends on the algorithm</i></li>
						  	</ol>
					
					  	  <br>
					<hr>

					</div>

					<br>

					<div class="animate-box" style="width:100%; height:100%;">
										<div id="agenda"></div>
						<center><h3>Day 2</h3></center>
						  <h4>Session 1 - Modeling</h4>

						  Use an AWS ML API service or Sagemaker to start your ML modeling journey. A list of services can be found <a href="https://aws.amazon.com/machine-learning/">here</a>.

						  <h5>Key steps involved are:</h5>
						  <ol>
						  	<li> Build </li>
						  	<li> Train </li>
						  	<li> Tune </li>
						  	<li> Deploy </li>
						  </ol>
						  <br>
						  If model involves Sagemaker, choosing a starting point (initial notebook) is important! See labs section below, and also choose from the several Sagemaker examples. <br> 

						  <h5>Questions to Consider </h5>	
						  	  <ul>
  								<li>Can you draw meaningful conclusions from this model?</li>
  								<li>Are there new insights or unusual patterns revealed by the model?</li>
  								<li>Where there execution problems for the model? How reasonable was the processing time?</li>
  								<li>Did the model have difficulties with data quality issues, such as a high number of missing values?</li>
  								<li>Were there any calculation inconsistencies that should be noted?</li>
						  	  </ul>
						  	  <br>


						  	  <h5> DELIVERABLES - Model Testing Report</h5>
						  	  <ol>
						  	  <li><i>Framework Used</i></li>
						  	  <li><i>Size of Model</i></li>
						  	  <li><i>Training time</i></li>
						  	  <li><i>Identify any built-in assumptions made by the selected technique/algorithm about the data (e.g. quality, format, distribution).</i></li>
						  	  <li><i>Record parameter settings used to produce winning model</i></li>
						  	  <li><i>Validation and/or Test Accuracy</i></li>
						  	  <li><i>Cost of training</i></li>
						  	  <li><i>Tuning job metrics</i></li>
						  	  </ol>
						  	  <br>

					<hr>
						  <h4>Session 2 - Evaluation</h4>
						  At this stage, you formalize your assessment of whether or not the project results meet the business success criteria. This step requires a clear understanding of the stated business goals, so be sure to include key decision makers in the project assessment.


						  	  <ul>

								<li>Are your results stated clearly and in a form that can be easily presented?</li>
							  	<li>Are there particularly novel or unique findings that should be highlighted?</li>
							  	<li>Can you rank the models and findings in order of their applicability to the business goals?</li>
							  	<li>In general, how well do these results answer your organization’s business goals?</li>
							  	<li>What additional questions have your results raised? How might you phrase these questions in business terms?</li>
							    <li>Did this stage contribute to the value of the final results?</li>
							  	<li>Are there ways to streamline or improve this particular stage or operation?</li>
							  	<li>What were the failures or mistakes of this phase? How can they be avoided next time?</li>
							  	<li>Were there dead ends, such as particular models that proved fruitless? Are there ways to predict such dead ends so that efforts can be directed more productively?</li>
							  	<li>Were there any surprises (both good and bad) during this phase? In hindsight, is there an obvious way to predict such occurences?</li>
							  	<li>Are there alternative decisions or strategies that might have been used in a given phase? Note such alternatives for future data mining projects.</li>

						  	  </ul>
						  	  <br>

						  	  <h5> DELIVERABLES - Evaluation report</h5>
						  	  <i>Optionally answer relevant questions from list above</i>
						  	  <br>
						  	  <h5> DECISION POINT </h5>

						  	  By now, you’ve produced a model, evaluated your model with test data, and may be wondering, Where to next? This phase helps you to answer that question in light of your business goals. Essentially, you have two choices at this point:

						  	  <ol>
  								<li><h5>Red pill - Continue to the deployment phase.</h5> The next phase will help you to incorporate the model results into your business process and produce a final report. </li>

  								<li><h5>Blue Pill - Go back and refine or replace your models.</h5> If you find that your results are almost, but not quite, optimal, consider another round of modeling. You can take what you’ve learned in this phase and use it to refine the models and produce better results.</li>
  							</ol>

								<i>Your decision at this point involves the accuracy and relevancy of the modeling results. If the results address your data mining and business goals, then you are ready for the deployment phase. Whatever decision you make, be sure to document the evaluation process thoroughly.</i>
					
					  	  <br>
					<hr>
					</div>


					<div class="animate-box" style="width:100%; height:100%;">
						<div id="agenda"></div>
						<center><h3>Day 3</h3></center>
						  <h4>Session 1 - Architecting</h4>

						  Now that you have an endpoint (either using Sagemaker or an API service on AWS) we will build a simple, serverless front end for your endpoint with Amazon Simple Storage Service (S3), Amazon API Gateway, and AWS Lambda. The web application will accept new input data and present the resulting inferences to an end user.

						  <i> Note that you may want to use notebooks to visualize your output to keep things simple, or use another architecture entirely! </i>
							
						 Follow <a href="https://aws.amazon.com/blogs/machine-learning/build-a-serverless-frontend-for-an-amazon-sagemaker-endpoint/">this</a> blogpost for a detailed guide. In this guide, once the endpoint is tested and ready for production, we will use the Chalice package to produce an API Gateway endpoint to trigger a Lambda function that will call our (SageMaker or other) endpoint producing a unique prediction. Finally, we’ll produce a static HTML form in Amazon S3 to serve as the user interface for our application. The end product will be a simple web app that can accept new user data and produce an on-demand prediction based on that data, which is returned to the user’s browser.


						<center><img src="images/generic_arch.png" style="width:50%"></center>
						  

					<hr>
						  <h4>Session 2 - Presentations!</h4>
						  Present your results from each of the above stages. Good luck!
						  
					<hr>
					</div>




					<div class="animate-box" style="width:100%; height:100%;">
					<div id="agenda"></div>

						<center><h3>Labs</h3></center>
						  <h4><a href="lab0.html">Lab 0 (Optional) - Deep Learning AMI with Keras and Jupyter</a></h4>
						  	  <i>&nbsp;&nbsp;Quick lab that runs through how to build a model using Deep Learning AMI on EC2 running Keras on a Jupyter notebbok
						  	  </i><br>
						  <h4><a href="lab1.html">Lab 1 - SageMaker Notebook Creation</a></h4>
						  <i>&nbsp;&nbsp;Setting up SageMaker notebook instance and S3 bucket for workshop
						  	  </i><br>
						  <h4><a href="lab2.html">Lab 2 - Built-in Algorithm - XGBoost</a></h4>
						  	  <i>&nbsp;&nbsp;Data Preparation and XGBoost to predict customer churn
						  	  </i><br>
						  <h4><a href="lab3.html">Lab 3 - Built-in Algorithm - Image Classification</a></h4>
						  	  <i>&nbsp;&nbsp;ResNet using the Caltech-256 dataset</i><br>
						  <h4><a href="lab4.html">Lab 4 - BYO-Script Tensorflow</a></h4>
						  	  <i>&nbsp;&nbsp;Image Classification with TensorBoard</i><br>
						  <h4><a href="lab5.html">Lab 5 - BYO-Script MXNet</a></h4>
						  	  <i>&nbsp;&nbsp;Handwriting recognition with test form</i><br>
						  <h4><a href="lab6.html">Lab 6 - Working with Redshift Data</a></h4>
						  	  <i>&nbsp;&nbsp;Using redshift to S3 transfers</i><br>
					</div> 
				</div>
			</div>
		</div>

		<footer id="sage-footer" class="js-sage-waypoint">
			<div class="container">
				<div class="row">
					<div class="col-md-12 text-center">
						<p><small>&copy; 2018, Amazon Web Services, Inc. or its affiliates. All rights reserved.</small> </p>
						<ul class="sage-social">
							<li>
								<a href="https://twitter.com/awscloud"><i class="icon-twitter"></i></a>
							</li>
							<li>
								<a href="https://www.instagram.com/amazonwebservices/"><i class="icon-instagram"></i></a>
							</li>
							<li>
								<a href="https://aws.amazon.com/blogs/aws/"><i class="icon-home"></i></a>
							</li>
						</ul>
					</div>
				</div>
			</div>
		</footer>

	</div>

	</body>
</html>

